{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e4031ae",
   "metadata": {},
   "source": [
    "## Building Document Q & A With Ollama and Docling\n",
    "\n",
    "1. Setting up Environment\n",
    "2. Importing Packages\n",
    "3. Mapping Document Format\n",
    "4. Convert PDF to Markdown\n",
    "5. Set up Q and A\n",
    "6. Invoke Q and A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed2be06",
   "metadata": {},
   "source": [
    "### Setting up Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c264b9",
   "metadata": {},
   "source": [
    "\n",
    "*!ollama install granite3.1-moe:latest* \\\n",
    "*!ollama install nomic-embed-text* \\\n",
    "*!pip install -q \"langchain>=0.1.0\" \"langchain-community>=0.0.13\" \"langchain-core>=0.1.17\" \"langchain-ollama>=0.0.1\" \"pdfminer.six>=20221105\" \"markdown>=3.5.2\" \"docling>=2.0.0\" \"beautifulsoup4>=4.12.0\" \"unstructured>=0.12.0\" \"chromadb>=0.4.22\" \"faiss-cpu>=1.7.4\"*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96983a0",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "664d4097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "\n",
    "import os\n",
    "\n",
    "import tempfile\n",
    "\n",
    "import shutil\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "\n",
    "# Docling imports\n",
    "\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions, TesseractCliOcrOptions\n",
    "\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption, WordFormatOption, SimplePipeline\n",
    "\n",
    "\n",
    "\n",
    "# LangChain imports\n",
    "\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_ollama import OllamaEmbeddings, OllamaLLM\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b749894",
   "metadata": {},
   "source": [
    "### Understanding Document Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1ffe972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_format(file_path) -> InputFormat:\n",
    "\n",
    "    \"\"\"Determine the document format based on file extension\"\"\"\n",
    "\n",
    "    try:\n",
    "\n",
    "        file_path = str(file_path)\n",
    "\n",
    "        extension = os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "        format_map = {\n",
    "\n",
    "            '.pdf': InputFormat.PDF,\n",
    "\n",
    "            '.docx': InputFormat.DOCX,\n",
    "\n",
    "            '.doc': InputFormat.DOCX,\n",
    "\n",
    "            '.pptx': InputFormat.PPTX,\n",
    "\n",
    "            '.html': InputFormat.HTML,\n",
    "\n",
    "            '.htm': InputFormat.HTML\n",
    "\n",
    "        }\n",
    "\n",
    "        return format_map.get(extension, None)\n",
    "\n",
    "    except:\n",
    "\n",
    "        return \"Error in get_document_format: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0416b880",
   "metadata": {},
   "source": [
    "### Converting PDF into Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95ec522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_document_to_markdown(doc_path) -> str:\n",
    "\n",
    "    \"\"\"Convert document to markdown using simplified pipeline\"\"\"\n",
    "\n",
    "    try:\n",
    "\n",
    "        # Convert to absolute path string\n",
    "\n",
    "        input_path = os.path.abspath(str(doc_path))\n",
    "\n",
    "        print(f\"Converting document: {doc_path}\")\n",
    "\n",
    "\n",
    "\n",
    "        # Create temporary directory for processing\n",
    "\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "\n",
    "            # Copy input file to temp directory\n",
    "\n",
    "            temp_input = os.path.join(temp_dir, os.path.basename(input_path))\n",
    "\n",
    "            shutil.copy2(input_path, temp_input)\n",
    "\n",
    "\n",
    "\n",
    "            # Configure pipeline options\n",
    "\n",
    "            pipeline_options = PdfPipelineOptions()\n",
    "\n",
    "            pipeline_options.do_ocr = False # Disable OCR temporarily\n",
    "\n",
    "            pipeline_options.do_table_structure = True\n",
    "\n",
    "\n",
    "\n",
    "            # Create converter with minimal options\n",
    "\n",
    "            converter = DocumentConverter(\n",
    "\n",
    "                allowed_formats=[\n",
    "\n",
    "                    InputFormat.PDF,\n",
    "\n",
    "                    InputFormat.DOCX,\n",
    "\n",
    "                    InputFormat.HTML,\n",
    "\n",
    "                    InputFormat.PPTX,\n",
    "\n",
    "                ],\n",
    "\n",
    "                format_options={\n",
    "\n",
    "                    InputFormat.PDF: PdfFormatOption(\n",
    "\n",
    "                        pipeline_options=pipeline_options,\n",
    "\n",
    "                    ),\n",
    "\n",
    "                    InputFormat.DOCX: WordFormatOption(\n",
    "\n",
    "                        pipeline_cls=SimplePipeline\n",
    "\n",
    "                    )\n",
    "\n",
    "                }\n",
    "\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            # Convert document\n",
    "\n",
    "            print(\"Starting conversion...\")\n",
    "\n",
    "            conv_result = converter.convert(temp_input)\n",
    "\n",
    "\n",
    "\n",
    "            if not conv_result or not conv_result.document:\n",
    "\n",
    "                raise ValueError(f\"Failed to convert document: {doc_path}\")\n",
    "\n",
    "\n",
    "\n",
    "            # Export to markdown\n",
    "\n",
    "            print(\"Exporting to markdown...\")\n",
    "\n",
    "            md = conv_result.document.export_to_markdown()\n",
    "\n",
    "\n",
    "\n",
    "            # Create output path\n",
    "\n",
    "            output_dir = os.path.dirname(input_path)\n",
    "\n",
    "            base_name = os.path.splitext(os.path.basename(input_path))[0]\n",
    "\n",
    "            md_path = os.path.join(output_dir, f\"{base_name}_converted.md\")\n",
    "\n",
    "\n",
    "\n",
    "            # Write markdown file\n",
    "\n",
    "            print(f\"Writing markdown to: {base_name}_converted.md\")\n",
    "\n",
    "            with open(md_path, \"w\", encoding=\"utf-8\") as fp:\n",
    "\n",
    "                fp.write(md)\n",
    "\n",
    "\n",
    "\n",
    "            return md_path\n",
    "\n",
    "    except:\n",
    "\n",
    "        return f\"Error converting document: {doc_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41930ccb",
   "metadata": {},
   "source": [
    "### Setting Q & A Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35bc5db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_qa_chain(markdown_path: Path, embeddings_model_name:str = \"nomic-embed-text:latest\", model_name: str = \"granite3.1-moe:latest\"):\n",
    "\n",
    "    \"\"\"Set up the QA chain for document processing\"\"\"\n",
    "\n",
    "    # Load and split the document\n",
    "\n",
    "    loader = UnstructuredMarkdownLoader(str(markdown_path))\n",
    "\n",
    "    documents = loader.load()\n",
    "\n",
    "\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "\n",
    "        chunk_size=1000,\n",
    "\n",
    "        chunk_overlap=200,\n",
    "\n",
    "        length_function=len,\n",
    "\n",
    "    )\n",
    "\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "\n",
    "\n",
    "\n",
    "    # Create embeddings and vector store\n",
    "\n",
    "    embeddings = OllamaEmbeddings(model=embeddings_model_name)\n",
    "\n",
    "    vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize LLM\n",
    "\n",
    "    llm = OllamaLLM(\n",
    "\n",
    "        model=model_name,\n",
    "\n",
    "        temperature=0\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Set up conversation memory\n",
    "\n",
    "    memory = ConversationBufferMemory(\n",
    "\n",
    "        memory_key=\"chat_history\",\n",
    "\n",
    "        output_key=\"answer\",\n",
    "\n",
    "        return_messages=True\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Create the chain\n",
    "\n",
    "    qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "\n",
    "        llm=llm,\n",
    "\n",
    "        retriever=vectorstore.as_retriever(             search_kwargs={\"k\": 10}             ),         memory=memory,\n",
    "\n",
    "        return_source_documents=True\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44d8dbd",
   "metadata": {},
   "source": [
    "### Function to Invoke QA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "508556a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(qa_chain, question: str):\n",
    "\n",
    "    \"\"\"Ask a question and display the answer\"\"\"\n",
    "\n",
    "    result = qa_chain.invoke({\"question\": question})\n",
    "\n",
    "    display(Markdown(f\"**Question:** {question}\\n\\n**Answer:** {result['answer']}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec382c0",
   "metadata": {},
   "source": [
    "### Testing Sample One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84cd3a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-11 15:10:20,668 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-10-11 15:10:20,674 - INFO - Going to convert document batch...\n",
      "2025-10-11 15:10:20,675 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 60c8066c482b9239b869b997da3fb1da\n",
      "2025-10-11 15:10:20,676 - INFO - Accelerator device: 'cuda:0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting document: /home/mayur/Downloads/System Design Playbook.pdf\n",
      "Starting conversion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-11 15:10:22,390 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-10-11 15:10:22,759 - INFO - Processing document System Design Playbook.pdf\n",
      "2025-10-11 15:10:25,777 - INFO - Finished converting document System Design Playbook.pdf in 5.11 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting to markdown...\n",
      "Writing markdown to: System Design Playbook_converted.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-11 15:10:27,173 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-10-11 15:10:27,283 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-10-11 15:10:29,753 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What is the main topic of this document?\n",
       "\n",
       "**Answer:** The main topic of this document is system design, focusing on various aspects such as secure password storage, microfrontends, Amazon S3 features, JWT usage, and payment systems like Apple Pay. It covers topics including how databases store passwords securely, the workings of Figma in scaling Postgres to 4 million users, DNS functionality, JWT implementation, microfrontends architecture, Amazon S3's durability mechanisms, Stripe's prevention of double payments, and Apple Pay's credit card handling process without storing sensitive details on devices."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-11 15:10:30,990 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-10-11 15:10:31,135 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-10-11 15:10:32,016 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What are the key points discussed?\n",
       "\n",
       "**Answer:** This document primarily discusses several key aspects of system design, including:\n",
       "\n",
       "1. **Password Storage and Security**: The use of hash functions for password storage and the importance of HTTPS for secure transmission (How Database Stores Passwords Securely).\n",
       "\n",
       "2. **Micro Frontends Architecture**: Explanation of how microfrontends extend the microservices concept to frontend development, enabling independent teams to own features from backend to frontend (How Micro Frontends Work).\n",
       "\n",
       "3. **Amazon S3 Durability and Data Replication**: Details about Amazon S3's architecture for achieving 99.999999999% durability through separate storage of metadata and file content, erasure coding, and other measures (How Amazon S3 Achieves 99.999999999% Durability).\n",
       "\n",
       "4. **JWT Authentication**: The process of creating and verifying JWTs for secure communication between parties (How JWT Works).\n",
       "\n",
       "5. **Database Design and Security**: Discussion on how databases store only the hashed password, not the actual password, and the use of salt to prevent rainbow table attacks (Database Stores Passwords Securely).\n",
       "\n",
       "6. **Microservices and Domain-Driven Design**: Explanation of how microservices architecture is applied in frontend development, along with the benefits of domain-driven design principles (How Micro Frontends Work).\n",
       "\n",
       "7. **Amazon S3 Features**: Description of Amazon S3's features like versioning, backups, and high availability for scalability and data integrity (How Amazon S3 Works).\n",
       "\n",
       "8. **Uber's ETA Calculation**: The method used by Uber to compute estimated times of arrival using a graph-based approach (How Uber Computes ETA).\n",
       "\n",
       "9. **DNS and Caching**: Explanation of the DNS workflow, including cache mechanisms at various levels (How DNS Works).\n",
       "\n",
       "10. **JWT Security Measures**: Discussion on additional security measures implemented in JWTs to prevent unauthorized access or data manipulation (How JWT Works).\n",
       "\n",
       "11. **Apple Pay and Secure Element**: Description of how Apple Pay securely handles credit card details by storing the unique number, DAN, in a secure element chip (Apple Pay Works).\n",
       "\n",
       "12. **Figma's Scalability Strategies**: Overview of Figma's strategies for scaling Postgres to support 4 million users, including vertical scaling, database replicas, caching layers, and connection pooling (How Figma Scaled)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-11 15:10:37,747 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-10-11 15:10:37,920 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-10-11 15:10:38,820 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** Can you summarize the conclusions?\n",
       "\n",
       "**Answer:** This document provides insights into various aspects of system design, focusing on secure password storage, microservices architecture (Micro Frontends), Amazon S3 durability and performance, JWT authentication, DNS, database optimization, and more. Here are the main takeaways:\n",
       "\n",
       "1. **Secure Password Storage**: Use a one-way hash function to transform passwords into fingerprints for storage in databases. Implement HTTPS for secure transmission of JWTs, set minimum roles and expiry times to minimize damage from stolen credentials, and maintain a denial list on the server to reject suspicious tokens.\n",
       "\n",
       "2. **Micro Frontends**: Extend microservices concept to frontend development by slicing site's frontend into self-contained, domain-driven microapps. Utilize technology agnostic frameworks like React or Angular, set boundaries based on business value, and support autonomous teams with shared libraries for code reuse and visual consistency.\n",
       "\n",
       "3. **Amazon S3 Durability**: Store metadata separately from file content to achieve 99.999999999% durability using erasure coding, replication, and free space management. Regularly monitor disk failure rates and maintain physical isolation of data centers for high recovery throughput.\n",
       "\n",
       "4. **JWT Authentication**: Represent the physical map as a graph and compute ETA by finding shortest paths in directed weighted graphs. Use cryptographic methods to validate location information sent via Bluetooth or Ultra Wideband, and handle DAN (Device Account Number) securely on the iPhone.\n",
       "\n",
       "5. **DNS and JWT**: DNS maps pre-computed fingerprints to passwords, while JWT uses a signature for authentication. Ensure HTTPS for secure transmission of JWTs and set minimum roles and expiry times to protect against stolen credentials.\n",
       "\n",
       "6. **Database Optimization**: Store only hashed password fingerprints in the database; regenerate and compare fingerprints when users enter new passwords. Add salt to passwords before hashing to prevent rainbow table attacks, and store salts alongside their corresponding fingerprints for verification.\n",
       "\n",
       "7. **Microservices Architecture (Micro Frontends)**: Extend microservices concept to frontend development by slicing site's frontend into self-contained, domain-driven microapps. Utilize technology agnostic frameworks like React or Angular, set boundaries based on business value, and support autonomous teams with shared libraries for code reuse and visual consistency.\n",
       "\n",
       "8. **Amazon S3**: Store unstructured data like log files in an object store using a distributed architecture to achieve high scalability and availability. Implement versioning and backups to reduce user mistakes, deploy changes only through durability reviews, and monitor disk failure rates for efficient repair services.\n",
       "\n",
       "9. **Uber's Finding Nearby Drivers**: Use a hexagonal-shaped hierarchical geospatial index (H3) to efficiently find nearby drivers by indexing locations. Divide Earth's surface into cells on a flat grid and use bitwise operations to switch between data resolutions in constant time, supporting different data resolutions with minimal impact on performance.\n",
       "\n",
       "10. **Apple Pay**: Don't store credit card details on the iPhone or Apple servers; instead, send it to the payment network. The payment network creates a unique number (DAN) to represent the credit card and iPhone. The iPhone stores DAN in a secure element for security, validating transactions by regenerating cryptograms using its DAN copy.\n",
       "\n",
       "11. **Apple AirTag**: An AirTag contains a low-power CPU and memory. It communicates via Bluetooth Low Energy instead of GPS or WiFi; location information is sent to the payment network as a cryptogram and transaction details. The iPhone validates transactions by regenerating the cryptogram using its DAN copy before sending it to the card reader.\n",
       "\n",
       "12. **Apple's Achieving 99.99999999% Cache Consistency**: Use a distributed cache for scalable reads, implement exponential back-off with jitter to avoid the thundering herd problem, and remove idempotency keys from the database after 24 hours for reuse.\n",
       "\n",
       "13. **Uber's Finding Nearby Drivers**: Uber uses a consistent hash ring for container image indexing, reducing cold start latency by 90%. They also find shared data between container image layers for optimal data delivery and lazy load containers to reduce cold start latency further."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Process a document\n",
    "\n",
    "doc_path = Path(\"/home/mayur/Downloads/System Design Playbook.pdf\") # Replace with your document path\n",
    "\n",
    "# Check format and process\n",
    "\n",
    "doc_format = get_document_format(doc_path)\n",
    "\n",
    "if doc_format:\n",
    "\n",
    "    md_path = convert_document_to_markdown(doc_path)\n",
    "\n",
    "    qa_chain = setup_qa_chain(md_path)\n",
    "\n",
    "\n",
    "\n",
    "    # Example questions\n",
    "\n",
    "    questions = [\n",
    "\n",
    "        \"What is the main topic of this document?\",\n",
    "\n",
    "        \"What are the key points discussed?\",\n",
    "\n",
    "        \"Can you summarize the conclusions?\"\n",
    "\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "    for question in questions:\n",
    "\n",
    "        ask_question(qa_chain, question)\n",
    "\n",
    "else:\n",
    "\n",
    "    print(f\"Unsupported document format: {doc_path.suffix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90e7cbe",
   "metadata": {},
   "source": [
    "## Testing Sample Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7f364ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-11 15:12:51,492 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-10-11 15:12:51,513 - INFO - Going to convert document batch...\n",
      "2025-10-11 15:12:51,515 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 60c8066c482b9239b869b997da3fb1da\n",
      "2025-10-11 15:12:51,515 - INFO - Accelerator device: 'cuda:0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting document: /home/mayur/Downloads/ai-pdf/ml-interview.pdf\n",
      "Starting conversion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-11 15:12:53,561 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-10-11 15:12:53,949 - INFO - Processing document ml-interview.pdf\n",
      "2025-10-11 15:13:00,334 - INFO - Finished converting document ml-interview.pdf in 8.84 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting to markdown...\n",
      "Writing markdown to: ml-interview_converted.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-11 15:13:00,984 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-10-11 15:13:01,098 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-10-11 15:13:01,752 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** what is the concept of temperature in LLM?\n",
       "\n",
       "**Answer:** Temperature in Large Language Models (LLMs) refers to a hyperparameter that controls the randomness of text generation by adjusting the probability distribution over possible next tokens. A low temperature (close to 0) makes the model highly deterministic, favoring the most probable tokens. Conversely, a high temperature (above 1) encourages more diversity by flattening the distribution, allowing less probable tokens to be selected. For instance, a temperature of 0.7 strikes a balance between creativity and coherence, making it suitable for generating diverse but sensible outputs.\n",
       "\n",
       "In summary, lower temperatures result in more predictable and consistent text generation, while higher temperatures introduce more variability and randomness into the model's output. This concept is crucial in LLM text generation as it allows users to control the level of creativity and diversity in the generated text."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Process a document\n",
    "\n",
    "doc_path = Path(\"/home/mayur/Downloads/ai-pdf/ml-interview.pdf\") # Replace with your document path\n",
    "\n",
    "# Check format and process\n",
    "\n",
    "doc_format = get_document_format(doc_path)\n",
    "\n",
    "if doc_format:\n",
    "\n",
    "    md_path = convert_document_to_markdown(doc_path)\n",
    "\n",
    "    qa_chain = setup_qa_chain(md_path)\n",
    "\n",
    "\n",
    "\n",
    "    # Example questions\n",
    "\n",
    "    questions = [\n",
    "\n",
    "        \"what is the concept of temperature in LLM?\"\n",
    "\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "    for question in questions:\n",
    "\n",
    "        ask_question(qa_chain, question)\n",
    "\n",
    "else:\n",
    "\n",
    "    print(f\"Unsupported document format: {doc_path.suffix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326a41f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
