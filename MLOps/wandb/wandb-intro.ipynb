{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10245fed",
   "metadata": {},
   "source": [
    "###  Weights and Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4bb966",
   "metadata": {},
   "source": [
    "### Tracking Experiments Using WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46c6166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log in to your W&B account\n",
    "import wandb\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "482a4a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a701ae4",
   "metadata": {},
   "source": [
    "### Tracking Dummy Machine Learning Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb9bf19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mayur/Documents/git-repo-with-ads/Explore-Libraries/MLOps/wandb/wandb/run-20251001_131411-fr4fman1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mlworks-org/basic-intro/runs/fr4fman1' target=\"_blank\">unique-rain-1</a></strong> to <a href='https://wandb.ai/mlworks-org/basic-intro' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mlworks-org/basic-intro' target=\"_blank\">https://wandb.ai/mlworks-org/basic-intro</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mlworks-org/basic-intro/runs/fr4fman1' target=\"_blank\">https://wandb.ai/mlworks-org/basic-intro/runs/fr4fman1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▅▇█████</td></tr><tr><td>loss</td><td>▇█▆▄▃▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.83354</td></tr><tr><td>loss</td><td>0.10415</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unique-rain-1</strong> at: <a href='https://wandb.ai/mlworks-org/basic-intro/runs/fr4fman1' target=\"_blank\">https://wandb.ai/mlworks-org/basic-intro/runs/fr4fman1</a><br> View project at: <a href='https://wandb.ai/mlworks-org/basic-intro' target=\"_blank\">https://wandb.ai/mlworks-org/basic-intro</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251001_131411-fr4fman1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "project=\"basic-intro\"\n",
    "config = {\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"CIFAR-100\",\n",
    "    \"epochs\": 10,\n",
    "}\n",
    "\n",
    "with wandb.init(project=project, config=config) as run:\n",
    "  # This block simulates a training loop logging metrics\n",
    "  epochs = 10\n",
    "  offset = random.random() / 5\n",
    "  for epoch in range(2, epochs):\n",
    "      acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "      loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "\n",
    "      # 2️. Log metrics from your script to W&B\n",
    "      run.log({\"acc\": acc, \"loss\": loss})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd65567f",
   "metadata": {},
   "source": [
    "### Tracking ML Experiment using PyTorch\n",
    "\n",
    "W&B runs automatically log metrics, system information, hyperparameters, terminal output and you’ll see an interactive table with model inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fe3d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c1d3d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "998f57d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T\n",
    "\n",
    "MNIST.mirrors = [\n",
    "    mirror for mirror in MNIST.mirrors if \"http://yann.lecun.com/\" not in mirror\n",
    "]\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def get_dataloader(is_train, batch_size, slice=5):\n",
    "    \"Get a training dataloader\"\n",
    "    full_dataset = MNIST(\n",
    "        root=\".\", train=is_train, transform=T.ToTensor(), download=True\n",
    "    )\n",
    "    sub_dataset = torch.utils.data.Subset(\n",
    "        full_dataset, indices=range(0, len(full_dataset), slice)\n",
    "    )\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset=sub_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True if is_train else False,\n",
    "        pin_memory=False,\n",
    "        num_workers=2,\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "\n",
    "def get_model(dropout):\n",
    "    \"A simple model\"\n",
    "    model = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(28 * 28, 256),\n",
    "        nn.BatchNorm1d(256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(256, 10),\n",
    "    ).to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def validate_model(model, valid_dl, loss_func, log_images=False, batch_idx=0):\n",
    "    \"Compute performance of the model on the validation dataset and log a wandb.Table\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.inference_mode():\n",
    "        correct = 0\n",
    "        for i, (images, labels) in enumerate(valid_dl):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass ➡\n",
    "            outputs = model(images)\n",
    "            val_loss += loss_func(outputs, labels) * labels.size(0)\n",
    "\n",
    "            # Compute accuracy and accumulate\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Log one batch of images to the dashboard, always same batch_idx.\n",
    "            if i == batch_idx and log_images:\n",
    "                log_image_table(images, predicted, labels, outputs.softmax(dim=1))\n",
    "    return val_loss / len(valid_dl.dataset), correct / len(valid_dl.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b69fad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_image_table(images, predicted, labels, probs):\n",
    "    \"Log a wandb.Table with (img, pred, target, scores)\"\n",
    "    # Create a wandb Table to log images, labels and predictions to\n",
    "    table = wandb.Table(\n",
    "        columns=[\"image\", \"pred\", \"target\"] + [f\"score_{i}\" for i in range(10)]\n",
    "    )\n",
    "    for img, pred, targ, prob in zip(\n",
    "        images.to(\"cpu\"), predicted.to(\"cpu\"), labels.to(\"cpu\"), probs.to(\"cpu\")\n",
    "    ):\n",
    "        table.add_data(wandb.Image(img[0].numpy() * 255), pred, targ, *prob.numpy())\n",
    "\n",
    "    with wandb.init() as run:\n",
    "        run.log({\"predictions_table\": table}, commit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d3fd0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mayur/Documents/git-repo-with-ads/Explore-Libraries/MLOps/wandb/wandb/run-20251001_132710-jx10coux</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mlworks-org/pytorch-intro/runs/jx10coux' target=\"_blank\">sweet-darkness-2</a></strong> to <a href='https://wandb.ai/mlworks-org/pytorch-intro' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mlworks-org/pytorch-intro' target=\"_blank\">https://wandb.ai/mlworks-org/pytorch-intro</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mlworks-org/pytorch-intro/runs/jx10coux' target=\"_blank\">https://wandb.ai/mlworks-org/pytorch-intro/runs/jx10coux</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 0.277, Valid Loss: 0.377812, Accuracy: 0.89\n",
      "Epoch: 2, Train Loss: 0.394, Valid Loss: 0.311924, Accuracy: 0.90\n",
      "Epoch: 3, Train Loss: 0.301, Valid Loss: 0.273264, Accuracy: 0.92\n",
      "Epoch: 4, Train Loss: 0.272, Valid Loss: 0.255016, Accuracy: 0.92\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>train/example_ct</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/train_loss</td><td>█▄▄▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▂▂▁▁▁▁▂▁▂▁▂▁▁▁▁▁</td></tr><tr><td>val/val_accuracy</td><td>▁▄▆█</td></tr><tr><td>val/val_loss</td><td>█▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>4.01064</td></tr><tr><td>train/example_ct</td><td>48128</td></tr><tr><td>train/train_loss</td><td>0.39767</td></tr><tr><td>val/val_accuracy</td><td>0.9245</td></tr><tr><td>val/val_loss</td><td>0.25502</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweet-darkness-2</strong> at: <a href='https://wandb.ai/mlworks-org/pytorch-intro/runs/jx10coux' target=\"_blank\">https://wandb.ai/mlworks-org/pytorch-intro/runs/jx10coux</a><br> View project at: <a href='https://wandb.ai/mlworks-org/pytorch-intro' target=\"_blank\">https://wandb.ai/mlworks-org/pytorch-intro</a><br>Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251001_132710-jx10coux/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mayur/Documents/git-repo-with-ads/Explore-Libraries/MLOps/wandb/wandb/run-20251001_132822-yk2wrvpu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mlworks-org/Explore-Libraries-MLOps_wandb/runs/yk2wrvpu' target=\"_blank\">classic-mountain-2</a></strong> to <a href='https://wandb.ai/mlworks-org/Explore-Libraries-MLOps_wandb' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mlworks-org/Explore-Libraries-MLOps_wandb' target=\"_blank\">https://wandb.ai/mlworks-org/Explore-Libraries-MLOps_wandb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mlworks-org/Explore-Libraries-MLOps_wandb/runs/yk2wrvpu' target=\"_blank\">https://wandb.ai/mlworks-org/Explore-Libraries-MLOps_wandb/runs/yk2wrvpu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classic-mountain-2</strong> at: <a href='https://wandb.ai/mlworks-org/Explore-Libraries-MLOps_wandb/runs/yk2wrvpu' target=\"_blank\">https://wandb.ai/mlworks-org/Explore-Libraries-MLOps_wandb/runs/yk2wrvpu</a><br> View project at: <a href='https://wandb.ai/mlworks-org/Explore-Libraries-MLOps_wandb' target=\"_blank\">https://wandb.ai/mlworks-org/Explore-Libraries-MLOps_wandb</a><br>Synced 5 W&B file(s), 1 media file(s), 258 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251001_132822-yk2wrvpu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Run (jx10coux) is finished. The call to `log` will be ignored. Please make sure that you are using an active run.\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "config = {\n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 128,\n",
    "    \"lr\": 1e-3,\n",
    "    \"dropout\": random.uniform(0.01, 0.80),\n",
    "}\n",
    "\n",
    "project = \"pytorch-intro\"\n",
    "\n",
    "# initialise a wandb run\n",
    "with wandb.init(project=project, config=config) as run:\n",
    "\n",
    "    try:\n",
    "        # Optionally copy your config\n",
    "        config = run.config\n",
    "\n",
    "        # Get the data\n",
    "        train_dl = get_dataloader(is_train=True, batch_size=config.batch_size)\n",
    "        valid_dl = get_dataloader(is_train=False, batch_size=2 * config.batch_size)\n",
    "        n_steps_per_epoch = math.ceil(len(train_dl.dataset) / config.batch_size)\n",
    "\n",
    "        # A simple MLP model\n",
    "        model = get_model(config.dropout)\n",
    "\n",
    "        # Make the loss and optimizer\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "        # Training\n",
    "        example_ct = 0\n",
    "        step_ct = 0\n",
    "        for epoch in range(config.epochs):\n",
    "            model.train()\n",
    "            for step, (images, labels) in enumerate(train_dl):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                train_loss = loss_func(outputs, labels)\n",
    "                optimizer.zero_grad()\n",
    "                train_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                example_ct += len(images)\n",
    "                metrics = {\n",
    "                    \"train/train_loss\": train_loss,\n",
    "                    \"train/epoch\": (step + 1 + (n_steps_per_epoch * epoch))\n",
    "                    / n_steps_per_epoch,\n",
    "                    \"train/example_ct\": example_ct,\n",
    "                }\n",
    "\n",
    "                if step + 1 < n_steps_per_epoch:\n",
    "                    # Log train metrics to wandb\n",
    "                    run.log(metrics)\n",
    "\n",
    "                step_ct += 1\n",
    "\n",
    "                val_loss, accuracy = validate_model(\n",
    "                    model, valid_dl, loss_func, log_images=(epoch == (config.epochs - 1))\n",
    "                )\n",
    "\n",
    "            # Log train and validation metrics to wandb\n",
    "            val_metrics = {\"val/val_loss\": val_loss, \"val/val_accuracy\": accuracy}\n",
    "            run.log({**metrics, **val_metrics})\n",
    "\n",
    "            # Save the model checkpoint to wandb\n",
    "            torch.save(model, \"my_model.pt\")\n",
    "            run.log_model(\n",
    "                \"./my_model.pt\",\n",
    "                \"my_mnist_model\",\n",
    "                aliases=[f\"epoch-{epoch+1}_dropout-{round(run.config.dropout, 4)}\"],\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                f\"Epoch: {epoch+1}, Train Loss: {train_loss:.3f}, Valid Loss: {val_loss:3f}, Accuracy: {accuracy:.2f}\"\n",
    "            )\n",
    "\n",
    "        # If you had a test set, this is how you could log it as a Summary metric\n",
    "        run.summary[\"test_accuracy\"] = 0.8\n",
    "\n",
    "    except wandb.errors.UsageError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    # finally:\n",
    "    #     run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750fb351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wandb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
